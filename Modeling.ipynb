{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQEDAL3R0heWMMLQypKkMd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeno1406/MachineLearning/blob/main/Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va6KRYraF2Z-",
        "outputId": "e09489c1-85de-4b8a-90d2-c51dd6e3e350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Mde55DGb6O",
        "outputId": "54077770-12cf-4788-d4f1-8001ca22843a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "BSNaW7ArF0uW"
      },
      "outputs": [],
      "source": [
        "#import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/student-mat.csv')"
      ],
      "metadata": {
        "id": "viOO8Y3NF5Yd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df[['failures', 'freetime', 'Medu', 'higher', 'studytime', 'schoolsup','famrel', 'Fjob', 'Mjob', 'traveltime','higher', 'Walc', 'Dalc']].copy()\n",
        "target = df.copy()['G1']"
      ],
      "metadata": {
        "id": "U_ukVYzUGIa9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo ColumnTransformer để áp dụng OneHotEncoder chỉ cho cột 'higher'\n",
        "categorical_features = ['failures', 'freetime', 'Medu', 'higher', 'studytime', 'schoolsup','famrel', 'Fjob', 'Mjob', 'traveltime','higher', 'Walc', 'Dalc'] # Danh sách các cột cần one-hot encoding\n",
        "features_encoded = pd.get_dummies(features, columns=categorical_features)\n",
        "# Check for duplicate columns\n",
        "if features_encoded.columns.duplicated().any():\n",
        "    print(\"Warning: Duplicate columns detected\")\n",
        "    features_encoded = features_encoded.loc[:, ~features_encoded.columns.duplicated()]\n",
        "features_encoded = features_encoded.astype(int)\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_encoded)\n",
        "print(features_encoded.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFsQ7MWENbQv",
        "outputId": "f014300e-2e26-468d-87d2-b0acf18b1330"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Duplicate columns detected\n",
            "   failures_0  failures_1  failures_2  failures_3  freetime_1  freetime_2  \\\n",
            "0           1           0           0           0           0           0   \n",
            "1           1           0           0           0           0           0   \n",
            "2           0           0           0           1           0           0   \n",
            "3           1           0           0           0           0           1   \n",
            "4           1           0           0           0           0           0   \n",
            "\n",
            "   freetime_3  freetime_4  freetime_5  Medu_0  ...  Walc_1  Walc_2  Walc_3  \\\n",
            "0           1           0           0       0  ...       1       0       0   \n",
            "1           1           0           0       0  ...       1       0       0   \n",
            "2           1           0           0       0  ...       0       0       1   \n",
            "3           0           0           0       0  ...       1       0       0   \n",
            "4           1           0           0       0  ...       0       1       0   \n",
            "\n",
            "   Walc_4  Walc_5  Dalc_1  Dalc_2  Dalc_3  Dalc_4  Dalc_5  \n",
            "0       0       0       1       0       0       0       0  \n",
            "1       0       0       1       0       0       0       0  \n",
            "2       0       0       0       1       0       0       0  \n",
            "3       0       0       1       0       0       0       0  \n",
            "4       0       0       1       0       0       0       0  \n",
            "\n",
            "[5 rows x 51 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cjUCPHOTGNHu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the models\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "xgbr = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "catbr = CatBoostRegressor(verbose=0, random_state=42)\n",
        "\n",
        "# Defining hyperparameter grids for RandomizedSearchCV\n",
        "param_dist_rf = {\n",
        "    'n_estimators': sp_randint(100, 500),\n",
        "    'max_depth': sp_randint(10, 50),\n",
        "    'min_samples_split': sp_randint(2, 20),\n",
        "    'min_samples_leaf': sp_randint(1, 20),\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "param_dist_xgb = {\n",
        "    'n_estimators': sp_randint(100, 500),\n",
        "    'max_depth': sp_randint(3, 20),\n",
        "    'learning_rate': sp_uniform(0.01, 0.3),\n",
        "    'subsample': sp_uniform(0.6, 0.4),\n",
        "    'colsample_bytree': sp_uniform(0.6, 0.4)\n",
        "}\n",
        "\n",
        "param_dist_cat = {\n",
        "    'iterations': sp_randint(500, 2000),\n",
        "    'depth': sp_randint(4, 10),\n",
        "    'learning_rate': sp_uniform(0.01, 0.3),\n",
        "    'l2_leaf_reg': sp_uniform(1, 10)\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV for RandomForest\n",
        "random_rf = RandomizedSearchCV(estimator=rf, param_distributions=param_dist_rf, n_iter=100, cv=3, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
        "random_rf.fit(X_train, y_train)\n",
        "best_rf = random_rf.best_estimator_\n",
        "\n",
        "# RandomizedSearchCV for XGBoost\n",
        "random_xgb = RandomizedSearchCV(estimator=xgbr, param_distributions=param_dist_xgb, n_iter=100, cv=3, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
        "random_xgb.fit(X_train, y_train)\n",
        "best_xgb = random_xgb.best_estimator_\n",
        "\n",
        "# RandomizedSearchCV for CatBoost\n",
        "random_cat = RandomizedSearchCV(estimator=catbr, param_distributions=param_dist_cat, n_iter=100, cv=3, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
        "random_cat.fit(X_train, y_train)\n",
        "best_cat = random_cat.best_estimator_\n",
        "\n",
        "# Making predictions\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "y_pred_cat = best_cat.predict(X_test)\n",
        "\n",
        "# Evaluating the models\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "mse_cat = mean_squared_error(y_test, y_pred_cat)\n",
        "\n",
        "print(f\"RandomForest Mean Squared Error: {mse_rf}\")\n",
        "print(f\"XGBoost Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"CatBoost Mean Squared Error: {mse_cat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZJZHnzEToA1",
        "outputId": "5492a7cd-0371-4de9-bc55-52ec3b0f44b1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Mean Squared Error: 11.060507147798235\n",
            "XGBoost Mean Squared Error: 11.221929391356307\n",
            "CatBoost Mean Squared Error: 10.445787749600305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot learning curves on the test set\n",
        "def plot_learning_curve_on_test(estimator, X_train, y_train, X_test, y_test, title):\n",
        "    train_sizes = np.linspace(0.1, 1.0, 5)\n",
        "    train_scores = []\n",
        "    test_scores = []\n",
        "\n",
        "    for train_size in train_sizes:\n",
        "        X_train_subset, _, y_train_subset, _ = train_test_split(X_train, y_train, train_size=train_size, random_state=42)\n",
        "        estimator.fit(X_train_subset, y_train_subset)\n",
        "        train_score = mean_squared_error(y_train_subset, estimator.predict(X_train_subset))\n",
        "        test_score = mean_squared_error(y_test, estimator.predict(X_test))\n",
        "        train_scores.append(train_score)\n",
        "        test_scores.append(test_score)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(train_sizes, train_scores, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores, 'o-', color=\"g\", label=\"Test score\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Mean Squared Error\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Plotting learning curves on the test set\n",
        "plot_learning_curve_on_test(best_rf, X_train, y_train, X_test, y_test, \"Learning Curve (RandomForest)\")\n",
        "plot_learning_curve_on_test(best_xgb, X_train, y_train, X_test, y_test, \"Learning Curve (XGBoost)\")\n",
        "plot_learning_curve_on_test(best_cat, X_train, y_train, X_test, y_test, \"Learning Curve (CatBoost)\")\n",
        "\n",
        "# Visualization for model comparison\n",
        "models = ['RandomForest', 'XGBoost', 'CatBoost']\n",
        "mses = [mse_rf, mse_xgb, mse_cat]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, mses, color=['blue', 'orange', 'green'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Model Comparison')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4Mh9bUb-T2I8",
        "outputId": "015618eb-e1ba-463e-b28a-b1fa225482fb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "train_size=1.0 should be either positive and smaller than the number of samples 316 or a float in the (0, 1) range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-a9b377ff39c3>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Plotting learning curves on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mplot_learning_curve_on_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Learning Curve (RandomForest)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mplot_learning_curve_on_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Learning Curve (XGBoost)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplot_learning_curve_on_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Learning Curve (CatBoost)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-a9b377ff39c3>\u001b[0m in \u001b[0;36mplot_learning_curve_on_test\u001b[0;34m(estimator, X_train, y_train, X_test, y_test, title)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mX_train_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m     ):\n\u001b[0;32m-> 2193\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2194\u001b[0m             \u001b[0;34m\"train_size={0} should be either positive and smaller\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m             \u001b[0;34m\" than the number of samples {1} or a float in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: train_size=1.0 should be either positive and smaller than the number of samples 316 or a float in the (0, 1) range"
          ]
        }
      ]
    }
  ]
}